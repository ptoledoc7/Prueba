{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptoledoc7/Prueba/blob/main/NaiveBayes_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuBAVnZp3mb5"
      },
      "source": [
        "# Text Mining with Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwBYOELq3mb8"
      },
      "source": [
        "Naive Bayes es un modelo bayesiano, es decir, probabilístico, donde las predicciones se basan en calcular probabilidades.\n",
        "\n",
        "Además, tal como su nombre indica, es un modelo Naive, es decir, ingénuo; esto es porque Naive Bayes asume que el efecto de una variable es independiente al resto de variables, de esta forma, el cálculo de las probabilidades es mucho más sencillo.\n",
        "\n",
        "En términos matemáticos, el cálculo de Naive Bayes se traduce en la siguiente fórmula, la cual se conoce como regla de Bayes:\n",
        "\n",
        "**𝑃(𝐴|𝐵) = (𝑃(𝐵|𝐴) * 𝑃(𝐴)) / 𝑃(𝐵)**\n",
        "\n",
        "- **P(A|B)**: probabilidad de que ocurra A sabiendo que B ya ha ocurrido.\n",
        "- **P(B|A)**: probabilidad de que ocurra B sabiendo que se ha dado A.\n",
        "- **P(A)**: probabilidad de que ocurra A.\n",
        "- **P(B)**: probabilidad de que ocurra B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAXumPNM3mb-"
      },
      "source": [
        "## Naive Bayes Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iO9Vzej_N9O"
      },
      "source": [
        "Pongamos que queremos clasificar mensajes de texto entre spam o no spam; para ello contamos con N mensajes diferentes, así pues, lo primero de todo es crear una tabla que nos indique cuántas veces ha aparecido cada palabra en los casos en los que el mensaje era Spam y cuántas veces han aparecido en los mensajes no Spam; supongamos que la tabla es la siguiente:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 8        | 5     | 3      | 1      |\n",
        "| Spam              | 2        | 1     | 0      | 4      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlCTkroD_ygR"
      },
      "source": [
        "Partiendo de esta tabla podemos calcular cómo de probable es que aparezca la palabra «Estimado» dentro de un mensaje «No Spam»; esto no es más que la proporción de veces que la palabra «Estimado» ha salido en los mensajes «No Spam»:\n",
        "\n",
        "𝑃(𝐸𝑠𝑡𝑖𝑚𝑎𝑑𝑜|𝑁𝑜𝑆𝑝𝑎𝑚) = 8/(8+5+3+1) = 0.47\n",
        "\n",
        "Si hiciésemos este mismo proceso para cada una de las palabras y cada una de las clases, terminaríamos obteniendo la siguiente tabla:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 0.47     | 0.29  | 0.18   | 0.06   |\n",
        "| Spam              | 0.29     | 0.14  | 0      | 0.57   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5tSI-wAaKU"
      },
      "source": [
        "Por otro lado, necesitaríamos también conocer la probabilidad de que una palabra sea Spam o no sea Spam, esto es, la proporción de palabras Spam y no Spam.\n",
        "\n",
        "𝑃𝑟𝑜𝑏(𝑁𝑜𝑆𝑝𝑎𝑚) = (8+5+3+1)/(8+5+3+1+2+1+0+4) = 17/(17+7) = 0.71\n",
        "\n",
        "𝑃𝑟𝑜𝑏(𝑆𝑝𝑎𝑚) = (2+1+0+4)/(8+5+3+1+2+1+0+4) = 7/(17+7) = 0.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FvbspsQAqdy"
      },
      "source": [
        "Con esta información, supongamos que nos llegase un mensaje con las palabras «Estimado Amigo»; ahora sí, podríamos aplicar la fórmula anterior para poder clasificar dicho mensaje. Veámoslo:\n",
        "\n",
        "𝑃(𝑁𝑜𝑆𝑝𝑎𝑚) × 𝑃(𝐸𝑠𝑡𝑖𝑚𝑎𝑑𝑜|𝑁𝑜𝑆𝑝𝑎𝑚) × 𝑃(𝐴𝑚𝑖𝑔𝑜|𝑁𝑜𝑆𝑝𝑎𝑚) = 0.71×0.47×0.29 = 0.10\n",
        "\n",
        "𝑃(𝑆𝑝𝑎𝑚) × 𝑃(𝐸𝑠𝑡𝑖𝑚𝑎𝑑𝑜|𝑆𝑝𝑎𝑚) × 𝑃(𝐴𝑚𝑖𝑔𝑜|𝑆𝑝𝑎𝑚) = 0.29×0.29×0.14 = 0.01\n",
        "\n",
        "Como vemos, es más probable que ese mensaje sea No Spam que Spam, por tanto, la predicción realizada por Naive Bayes es que ese mensaje no es Spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEssyOASBU2z"
      },
      "source": [
        "**Problemas con probabilidades de cero**\n",
        "\n",
        "Seguramente el funcionamiento de Naive Bayes te sea intuitivo y tenga sentido; sin embargo, ¿qué hubiese pasado si el mensaje que nos llega tiene las palabras «Dinero», «Comida» y «Dinero»? Veamoslo:\n",
        "\n",
        "𝑃(𝑁𝑜𝑆𝑝𝑎𝑚) = 0.71×0.06×0.18×0.06 = 0.0004\n",
        "\n",
        "𝑃(𝑆𝑝𝑎𝑚) = 0.29×0.57×0.0×0.57 = 0\n",
        "\n",
        "Como vemos, por mucho que intuitivamente el mensaje sea Spam, puesto que la palabra «Dinero» aparece mucho en mensajes Spam, el mensaje será clasificado como «No Spam»; esto es debido a que la palabra «Comida» nunca ha aparecido en un mensaje Spam, por lo que su probabilidad es de cero, haciendo que la probabilidad del mensaje sea de cero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUWYQr_tBnAd"
      },
      "source": [
        "Para solucionar este problema se aplica Laplace; Laplace consiste, básicamente, en sumar 1 a todas las observaciones, de esta forma, sus probabilidades dejan de ser cero y nos evitamos el problema anterior. Veámoslo:\n",
        "\n",
        "Tabla de Frecuencias sin Aplicar Laplace:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 8        | 5     | 3      | 1      |\n",
        "| Spam              | 2        | 1     | 0      | 4      |\n",
        "\n",
        "Tabla de Frecuencias Aplicando Laplace:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 9        | 6     | 4      | 2      |\n",
        "| Spam              | 3        | 2     | 1      | 5      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm8YipECFmz"
      },
      "source": [
        "Como ves, ahora todas las variables han aparecido al menos una vez, de tal forma que si calculamos las probabilidades no existe ninguna variable con probabilidad de cero:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 0.43     | 0.29  | 0.19   | 0.10   |\n",
        "| Spam              | 0.27     | 0.18  | 0.09   | 0.45   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbspziKP3mb-"
      },
      "source": [
        "Ahora, si volvemos a clasificar el mensaje con las palabras «Dinero», «Comida» y «Dinero» obtendremos la siguiente predicción:\n",
        "\n",
        "𝑃(𝑁𝑜𝑆𝑝𝑎𝑚) = 0.66×0.10×0.19×0.10 = 0.0012\n",
        "\n",
        "𝑃(𝑆𝑝𝑎𝑚) = 0.34×0.45×0.09×0.45 = 0.0062\n",
        "\n",
        "Como puedes ver, gracias a aplicar Laplace el mensaje ha pasado de ser clasificado (incorrectamente) como «No Spam» a ser clasificado (correctamente) como «Spam»."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_pMfoUITW8"
      },
      "source": [
        "## Advantages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL3DtAJdITbU"
      },
      "source": [
        "- Es un modelo muy fácilmente interpretable, lo cual es un punto muy positivo sobre todo de cara a NLP, donde existen pocas opciones alternativas que también sean interpretables.\n",
        "\n",
        "- Es un modelo muy sencillo de entrenar y de ajustar sus hiperparámetros, y aún así puede dar muy buenos resultados, tal como hemos visto en el ejemplo anterior.\n",
        "\n",
        "- Trabaja muy bien para datasets con muchas variables, lo cual es poco común dentro de los modelos de Machine Learning, una vez más, esto lo hace muy interesante de cara a NLP.\n",
        "\n",
        "- Sirve tanto para problemas de clasificación binaria, como clasificación multiclase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQIJT-LcIToH"
      },
      "source": [
        "## Disadvantages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtDoCsYYITuL"
      },
      "source": [
        "- La asunción de que las variables son independientes, en la gran mayoria de casos esta asunción no se cumple.\n",
        "\n",
        "- Aparición de nuevas palabras o clases, en el caso de proyectos de NLP es muy normal que a la hora de realizar predicciones aparezcan nuevas palabras que el modelo no ha visto a la hora de entrenar, como resultado, el modelo no tendra en cuenta dichas palabras de cara a hacer las predicciones, por lo que habrá que reentrenarlo de forma frecuente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVnbikCItzx"
      },
      "source": [
        "Sin duda alguna Naive Bayes es un modelo muy sencillo de entender, interpretar y aplicar; por normal general, no suele ser un modelo que funcione muy bien en proyectos de clasificación; sin embargo, cuando se trata de clasificar texto, Naive Bayes es, el primero modelo que se debería probar.\n",
        "\n",
        "En cualquier caso, cuando se trata de un proyecto de clasificación de texto, siempre es interesante probar otro tipo de modelos (como los Support Vector Classifiers) y prestar mucha atención al proceso de limpieza y calidad de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj_79P5L3mb-"
      },
      "source": [
        "# NLTK Library for NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ItyhmbkCXss"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import FreqDist\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85EdvmUD5tL",
        "outputId": "5e4baab9-af1c-46b4-8e95-a24327d006e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c-t6vNKDIfD"
      },
      "source": [
        "Una vez que se tienen los datos, lo primero de todo es procesarlos; si bien el procesamiento de datos es un paso fundamental en todo proyecto de Machine Learning, en los proyectos de NLP (como este) procesar los datos resulta aún mucho más importante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v16xfrivEh57"
      },
      "outputs": [],
      "source": [
        "texto = \"NLTK es una biblioteca poderosa para procesamiento de lenguaje natural en Python.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuW-s0eGDJQi"
      },
      "source": [
        "## Tokenización\n",
        "\n",
        "Consiste en separar los mensajes en palabras para así poder tratar cada una de las palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr2efh8PDJYE",
        "outputId": "acec3121-f4b9-4622-e5dd-ac236c14dc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'poderosa', 'para', 'procesamiento', 'de', 'lenguaje', 'natural', 'en', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "tokens = word_tokenize(texto, language='spanish')\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDigBB9xEBXQ"
      },
      "source": [
        "## Stop Words\n",
        "\n",
        "La eliminación de palabras que no aportan valor (preposiciones, conjunciones, etc.); esto se realiza puesto que aumentaría mucho el tamaño de un dataset (ya de por sí son grandes) y no aportaría ningún valor, solo ruido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYjUOGPqEBf5",
        "outputId": "6d8a7597-781b-4a10-e827-288416794751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'biblioteca', 'poderosa', 'procesamiento', 'lenguaje', 'natural', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzQKs1DnE8g0"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "Consiste en la eliminación de las terminaciones de las palabras para quedarnos únicamnete con la raíz; siguiendo el caso anterior, en ambos casos (bueno, buena) nos quedaríamos con «buen»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcobFUTmE8nc",
        "outputId": "d27c5f42-6138-40f1-96ba-ace8cbef72ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nltk', 'bibliotec', 'poder', 'proces', 'lenguaj', 'natural', 'python', '.']\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdJZYQYSF1Mx"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "Es más utilizado en proyectos de NLP en inglés, ya que en este idioma bueno (good), mejor (better) y el mejor (best) son palabras completamente diferentes; en estos casos el stemming no funcionaría, así pues, la lematización convertiría todas esas palabras a su base (good), de tal forma que pasen a significar lo mismo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxCQLAtyF1VJ",
        "outputId": "bc3995ce-73c0-4660-d557-272f910f83e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'biblioteca', 'poderosa', 'procesamiento', 'lenguaje', 'natural', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()  # La lemmatización en español puede no ser tan efectiva como en inglés\n",
        "\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HayeFD8jF6Af"
      },
      "source": [
        "## Frequency Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKV97ICWF6GG",
        "outputId": "940546c9-f1dd-4748-a1f1-5b9009a51a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 8 samples and 8 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(lemmatized_tokens)\n",
        "print(freq_dist)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Master_IA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e64b965d7e995bad43a9ca3ca7cd680da294744a20b8df15a8a0eb6143941981"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}