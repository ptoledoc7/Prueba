{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptoledoc7/Prueba/blob/main/NaiveBayes_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuBAVnZp3mb5"
      },
      "source": [
        "# Text Mining with Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwBYOELq3mb8"
      },
      "source": [
        "Naive Bayes es un modelo bayesiano, es decir, probabilÃ­stico, donde las predicciones se basan en calcular probabilidades.\n",
        "\n",
        "AdemÃ¡s, tal como su nombre indica, es un modelo Naive, es decir, ingÃ©nuo; esto es porque Naive Bayes asume que el efecto de una variable es independiente al resto de variables, de esta forma, el cÃ¡lculo de las probabilidades es mucho mÃ¡s sencillo.\n",
        "\n",
        "En tÃ©rminos matemÃ¡ticos, el cÃ¡lculo de Naive Bayes se traduce en la siguiente fÃ³rmula, la cual se conoce como regla de Bayes:\n",
        "\n",
        "**ğ‘ƒ(ğ´|ğµ) = (ğ‘ƒ(ğµ|ğ´) * ğ‘ƒ(ğ´)) / ğ‘ƒ(ğµ)**\n",
        "\n",
        "- **P(A|B)**: probabilidad de que ocurra A sabiendo que B ya ha ocurrido.\n",
        "- **P(B|A)**: probabilidad de que ocurra B sabiendo que se ha dado A.\n",
        "- **P(A)**: probabilidad de que ocurra A.\n",
        "- **P(B)**: probabilidad de que ocurra B."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAXumPNM3mb-"
      },
      "source": [
        "## Naive Bayes Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iO9Vzej_N9O"
      },
      "source": [
        "Pongamos que queremos clasificar mensajes de texto entre spam o no spam; para ello contamos con N mensajes diferentes, asÃ­ pues, lo primero de todo es crear una tabla que nos indique cuÃ¡ntas veces ha aparecido cada palabra en los casos en los que el mensaje era Spam y cuÃ¡ntas veces han aparecido en los mensajes no Spam; supongamos que la tabla es la siguiente:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 8        | 5     | 3      | 1      |\n",
        "| Spam              | 2        | 1     | 0      | 4      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlCTkroD_ygR"
      },
      "source": [
        "Partiendo de esta tabla podemos calcular cÃ³mo de probable es que aparezca la palabra Â«EstimadoÂ» dentro de un mensaje Â«No SpamÂ»; esto no es mÃ¡s que la proporciÃ³n de veces que la palabra Â«EstimadoÂ» ha salido en los mensajes Â«No SpamÂ»:\n",
        "\n",
        "ğ‘ƒ(ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘‘ğ‘œ|ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) = 8/(8+5+3+1) = 0.47\n",
        "\n",
        "Si hiciÃ©semos este mismo proceso para cada una de las palabras y cada una de las clases, terminarÃ­amos obteniendo la siguiente tabla:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 0.47     | 0.29  | 0.18   | 0.06   |\n",
        "| Spam              | 0.29     | 0.14  | 0      | 0.57   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5tSI-wAaKU"
      },
      "source": [
        "Por otro lado, necesitarÃ­amos tambiÃ©n conocer la probabilidad de que una palabra sea Spam o no sea Spam, esto es, la proporciÃ³n de palabras Spam y no Spam.\n",
        "\n",
        "ğ‘ƒğ‘Ÿğ‘œğ‘(ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) = (8+5+3+1)/(8+5+3+1+2+1+0+4) = 17/(17+7) = 0.71\n",
        "\n",
        "ğ‘ƒğ‘Ÿğ‘œğ‘(ğ‘†ğ‘ğ‘ğ‘š) = (2+1+0+4)/(8+5+3+1+2+1+0+4) = 7/(17+7) = 0.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FvbspsQAqdy"
      },
      "source": [
        "Con esta informaciÃ³n, supongamos que nos llegase un mensaje con las palabras Â«Estimado AmigoÂ»; ahora sÃ­, podrÃ­amos aplicar la fÃ³rmula anterior para poder clasificar dicho mensaje. VeÃ¡moslo:\n",
        "\n",
        "ğ‘ƒ(ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) Ã— ğ‘ƒ(ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘‘ğ‘œ|ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) Ã— ğ‘ƒ(ğ´ğ‘šğ‘–ğ‘”ğ‘œ|ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) = 0.71Ã—0.47Ã—0.29 = 0.10\n",
        "\n",
        "ğ‘ƒ(ğ‘†ğ‘ğ‘ğ‘š) Ã— ğ‘ƒ(ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘‘ğ‘œ|ğ‘†ğ‘ğ‘ğ‘š) Ã— ğ‘ƒ(ğ´ğ‘šğ‘–ğ‘”ğ‘œ|ğ‘†ğ‘ğ‘ğ‘š) = 0.29Ã—0.29Ã—0.14 = 0.01\n",
        "\n",
        "Como vemos, es mÃ¡s probable que ese mensaje sea No Spam que Spam, por tanto, la predicciÃ³n realizada por Naive Bayes es que ese mensaje no es Spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEssyOASBU2z"
      },
      "source": [
        "**Problemas con probabilidades de cero**\n",
        "\n",
        "Seguramente el funcionamiento de Naive Bayes te sea intuitivo y tenga sentido; sin embargo, Â¿quÃ© hubiese pasado si el mensaje que nos llega tiene las palabras Â«DineroÂ», Â«ComidaÂ» y Â«DineroÂ»? Veamoslo:\n",
        "\n",
        "ğ‘ƒ(ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) = 0.71Ã—0.06Ã—0.18Ã—0.06 = 0.0004\n",
        "\n",
        "ğ‘ƒ(ğ‘†ğ‘ğ‘ğ‘š) = 0.29Ã—0.57Ã—0.0Ã—0.57 = 0\n",
        "\n",
        "Como vemos, por mucho que intuitivamente el mensaje sea Spam, puesto que la palabra Â«DineroÂ» aparece mucho en mensajes Spam, el mensaje serÃ¡ clasificado como Â«No SpamÂ»; esto es debido a que la palabra Â«ComidaÂ» nunca ha aparecido en un mensaje Spam, por lo que su probabilidad es de cero, haciendo que la probabilidad del mensaje sea de cero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUWYQr_tBnAd"
      },
      "source": [
        "Para solucionar este problema se aplica Laplace; Laplace consiste, bÃ¡sicamente, en sumar 1 a todas las observaciones, de esta forma, sus probabilidades dejan de ser cero y nos evitamos el problema anterior. VeÃ¡moslo:\n",
        "\n",
        "Tabla de Frecuencias sin Aplicar Laplace:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 8        | 5     | 3      | 1      |\n",
        "| Spam              | 2        | 1     | 0      | 4      |\n",
        "\n",
        "Tabla de Frecuencias Aplicando Laplace:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 9        | 6     | 4      | 2      |\n",
        "| Spam              | 3        | 2     | 1      | 5      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm8YipECFmz"
      },
      "source": [
        "Como ves, ahora todas las variables han aparecido al menos una vez, de tal forma que si calculamos las probabilidades no existe ninguna variable con probabilidad de cero:\n",
        "\n",
        "| Tipo de Documento | Estimado | Amigo | Comida | Dinero |\n",
        "|-------------------|----------|-------|--------|--------|\n",
        "| No Spam           | 0.43     | 0.29  | 0.19   | 0.10   |\n",
        "| Spam              | 0.27     | 0.18  | 0.09   | 0.45   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbspziKP3mb-"
      },
      "source": [
        "Ahora, si volvemos a clasificar el mensaje con las palabras Â«DineroÂ», Â«ComidaÂ» y Â«DineroÂ» obtendremos la siguiente predicciÃ³n:\n",
        "\n",
        "ğ‘ƒ(ğ‘ğ‘œğ‘†ğ‘ğ‘ğ‘š) = 0.66Ã—0.10Ã—0.19Ã—0.10 = 0.0012\n",
        "\n",
        "ğ‘ƒ(ğ‘†ğ‘ğ‘ğ‘š) = 0.34Ã—0.45Ã—0.09Ã—0.45 = 0.0062\n",
        "\n",
        "Como puedes ver, gracias a aplicar Laplace el mensaje ha pasado de ser clasificado (incorrectamente) como Â«No SpamÂ» a ser clasificado (correctamente) como Â«SpamÂ»."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t_pMfoUITW8"
      },
      "source": [
        "## Advantages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL3DtAJdITbU"
      },
      "source": [
        "- Es un modelo muy fÃ¡cilmente interpretable, lo cual es un punto muy positivo sobre todo de cara a NLP, donde existen pocas opciones alternativas que tambiÃ©n sean interpretables.\n",
        "\n",
        "- Es un modelo muy sencillo de entrenar y de ajustar sus hiperparÃ¡metros, y aÃºn asÃ­ puede dar muy buenos resultados, tal como hemos visto en el ejemplo anterior.\n",
        "\n",
        "- Trabaja muy bien para datasets con muchas variables, lo cual es poco comÃºn dentro de los modelos de Machine Learning, una vez mÃ¡s, esto lo hace muy interesante de cara a NLP.\n",
        "\n",
        "- Sirve tanto para problemas de clasificaciÃ³n binaria, como clasificaciÃ³n multiclase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQIJT-LcIToH"
      },
      "source": [
        "## Disadvantages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtDoCsYYITuL"
      },
      "source": [
        "- La asunciÃ³n de que las variables son independientes, en la gran mayoria de casos esta asunciÃ³n no se cumple.\n",
        "\n",
        "- ApariciÃ³n de nuevas palabras o clases, en el caso de proyectos de NLP es muy normal que a la hora de realizar predicciones aparezcan nuevas palabras que el modelo no ha visto a la hora de entrenar, como resultado, el modelo no tendra en cuenta dichas palabras de cara a hacer las predicciones, por lo que habrÃ¡ que reentrenarlo de forma frecuente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVnbikCItzx"
      },
      "source": [
        "Sin duda alguna Naive Bayes es un modelo muy sencillo de entender, interpretar y aplicar; por normal general, no suele ser un modelo que funcione muy bien en proyectos de clasificaciÃ³n; sin embargo, cuando se trata de clasificar texto, Naive Bayes es, el primero modelo que se deberÃ­a probar.\n",
        "\n",
        "En cualquier caso, cuando se trata de un proyecto de clasificaciÃ³n de texto, siempre es interesante probar otro tipo de modelos (como los Support Vector Classifiers) y prestar mucha atenciÃ³n al proceso de limpieza y calidad de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj_79P5L3mb-"
      },
      "source": [
        "# NLTK Library for NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ItyhmbkCXss"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import FreqDist\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85EdvmUD5tL",
        "outputId": "5e4baab9-af1c-46b4-8e95-a24327d006e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c-t6vNKDIfD"
      },
      "source": [
        "Una vez que se tienen los datos, lo primero de todo es procesarlos; si bien el procesamiento de datos es un paso fundamental en todo proyecto de Machine Learning, en los proyectos de NLP (como este) procesar los datos resulta aÃºn mucho mÃ¡s importante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v16xfrivEh57"
      },
      "outputs": [],
      "source": [
        "texto = \"NLTK es una biblioteca poderosa para procesamiento de lenguaje natural en Python.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuW-s0eGDJQi"
      },
      "source": [
        "## TokenizaciÃ³n\n",
        "\n",
        "Consiste en separar los mensajes en palabras para asÃ­ poder tratar cada una de las palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr2efh8PDJYE",
        "outputId": "acec3121-f4b9-4622-e5dd-ac236c14dc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'poderosa', 'para', 'procesamiento', 'de', 'lenguaje', 'natural', 'en', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "tokens = word_tokenize(texto, language='spanish')\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDigBB9xEBXQ"
      },
      "source": [
        "## Stop Words\n",
        "\n",
        "La eliminaciÃ³n de palabras que no aportan valor (preposiciones, conjunciones, etc.); esto se realiza puesto que aumentarÃ­a mucho el tamaÃ±o de un dataset (ya de por sÃ­ son grandes) y no aportarÃ­a ningÃºn valor, solo ruido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYjUOGPqEBf5",
        "outputId": "6d8a7597-781b-4a10-e827-288416794751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'biblioteca', 'poderosa', 'procesamiento', 'lenguaje', 'natural', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzQKs1DnE8g0"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "Consiste en la eliminaciÃ³n de las terminaciones de las palabras para quedarnos Ãºnicamnete con la raÃ­z; siguiendo el caso anterior, en ambos casos (bueno, buena) nos quedarÃ­amos con Â«buenÂ»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcobFUTmE8nc",
        "outputId": "d27c5f42-6138-40f1-96ba-ace8cbef72ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nltk', 'bibliotec', 'poder', 'proces', 'lenguaj', 'natural', 'python', '.']\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdJZYQYSF1Mx"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "Es mÃ¡s utilizado en proyectos de NLP en inglÃ©s, ya que en este idioma bueno (good), mejor (better) y el mejor (best) son palabras completamente diferentes; en estos casos el stemming no funcionarÃ­a, asÃ­ pues, la lematizaciÃ³n convertirÃ­a todas esas palabras a su base (good), de tal forma que pasen a significar lo mismo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxCQLAtyF1VJ",
        "outputId": "bc3995ce-73c0-4660-d557-272f910f83e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NLTK', 'biblioteca', 'poderosa', 'procesamiento', 'lenguaje', 'natural', 'Python', '.']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()  # La lemmatizaciÃ³n en espaÃ±ol puede no ser tan efectiva como en inglÃ©s\n",
        "\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HayeFD8jF6Af"
      },
      "source": [
        "## Frequency Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKV97ICWF6GG",
        "outputId": "940546c9-f1dd-4748-a1f1-5b9009a51a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FreqDist with 8 samples and 8 outcomes>\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(lemmatized_tokens)\n",
        "print(freq_dist)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Master_IA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e64b965d7e995bad43a9ca3ca7cd680da294744a20b8df15a8a0eb6143941981"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}